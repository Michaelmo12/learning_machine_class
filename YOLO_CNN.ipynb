{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO + CNN Classification Project\n",
    "## זיהוי אובייקטים עם YOLO וסיווג עם CNN\n",
    "\n",
    "### משימות:\n",
    "1. זיהוי אובייקט עיקרי עם YOLO\n",
    "2. יצירת דאטהסט CSV עם הגבלה ל-10 קטגוריות\n",
    "3. הכנת דאטהסט ללמידת מכונה (X, Y)\n",
    "4. בניית רשת CNN\n",
    "5. הערכת המודל על validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: התקנת חבילות"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# התקנת החבילות הנדרשות\n",
    "!pip install ultralytics tensorflow scikit-learn pandas matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# TensorFlow / Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: משימה 1 - זיהוי אובייקט עיקרי עם YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_main_object_in_images(model, image_dir, output_file):\n",
    "    \"\"\"\n",
    "    מריץ YOLO על כל התמונות בתיקייה ומזהה את האובייקט העיקרי\n",
    "    \"\"\"\n",
    "    results_dict = {}\n",
    "    # קבלת כל קבצי התמונות בתיקייה\n",
    "    image_paths = list(Path(image_dir).rglob(\"*.jpg\")) + list(Path(image_dir).rglob(\"*.png\"))\n",
    "\n",
    "    print(f\"מעבד {len(image_paths)} תמונות מתיקייה: {image_dir}\")\n",
    "\n",
    "    # עיבוד כל תמונה\n",
    "    for idx, img_path in enumerate(image_paths, 1):\n",
    "        # הדפסת התקדמות כל 50 תמונות\n",
    "        if idx % 50 == 0:\n",
    "            print(f\"מעובדות תמונה {idx}/{len(image_paths)}\")\n",
    "        \n",
    "        try:\n",
    "\n",
    "            # הרצת YOLO על התמונה\n",
    "            results = model(str(img_path), verbose=False)\n",
    "\n",
    "            # מציאת האובייקט העיקרי (בעל ה-confidence הגבוה ביותר)\n",
    "            if len(results) > 0 and len(results[0].boxes) > 0:\n",
    "                boxes = results[0].boxes\n",
    "                confidences = boxes.conf.cpu().numpy()\n",
    "                \n",
    "                if len(confidences) > 0:\n",
    "                    main_obj_idx = confidences.argmax()\n",
    "                    main_class_id = int(boxes.cls[main_obj_idx].cpu().numpy())\n",
    "                    main_confidence = float(confidences[main_obj_idx])\n",
    "                    main_class_name = model.names[main_class_id]\n",
    "\n",
    "                    results_dict[str(img_path)] = {\n",
    "                        \"class_name\": main_class_name,\n",
    "                        \"class_id\": main_class_id,\n",
    "                        \"confidence\": main_confidence,\n",
    "                        \"bbox\": boxes.xyxy[main_obj_idx].cpu().numpy().tolist()\n",
    "                    }\n",
    "                else:\n",
    "                    results_dict[str(img_path)] = {\"class_name\": \"unknown\", \"confidence\": 0.0}\n",
    "            else:\n",
    "                results_dict[str(img_path)] = {\"class_name\": \"unknown\", \"confidence\": 0.0}\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "            results_dict[str(img_path)] = {\"class_name\": \"unknown\", \"confidence\": 0.0}\n",
    "\n",
    "    # שמירת התוצאות לקובץ JSON\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results_dict, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"התוצאות נשמרו ב: {output_file}\")\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# טעינת מודל YOLO\n",
    "print(\"טוען מודל YOLO...\")\n",
    "yolo_model = YOLO('yolov8n.pt')\n",
    "\n",
    "# נתיבים\n",
    "train_dir = \"resources/images/data/train\"\n",
    "test_dir = \"resources/images/data/test\"\n",
    "val_dir = \"resources/images/data/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# הרצה על train\n",
    "print(\"\\n=== מעבד תמונות TRAIN ===\")\n",
    "train_results = detect_main_object_in_images(\n",
    "    yolo_model,\n",
    "    train_dir,\n",
    "    \"train_detections.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# הרצה על test\n",
    "print(\"\\n=== מעבד תמונות TEST ===\")\n",
    "test_results = detect_main_object_in_images(\n",
    "    yolo_model,\n",
    "    test_dir,\n",
    "    \"test_detections.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# הרצה על validation\n",
    "print(\"\\n=== מעבד תמונות VALIDATION ===\")\n",
    "val_results = detect_main_object_in_images(\n",
    "    yolo_model,\n",
    "    val_dir,\n",
    "    \"val_detections.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: משימה 2 - יצירת CSV והגבלה ל-10 קטגוריות"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv_with_top_categories(results_dict, output_csv, max_categories=10):\n",
    "    \"\"\"\n",
    "    יוצר CSV עם מזהה תמונה ואובייקט עיקרי, מגביל ל-10 קטגוריות\n",
    "    \"\"\"\n",
    "    # יצירת רשימת כל האובייקטים\n",
    "    data = []\n",
    "    for img_path, result in results_dict.items():\n",
    "        image_id = Path(img_path).stem  # שם הקובץ ללא סיומת\n",
    "        class_name = result.get('class_name', 'unknown')\n",
    "        confidence = result.get('confidence', 0.0)\n",
    "        data.append({\n",
    "            'image_id': image_id,\n",
    "            'image_path': img_path,\n",
    "            'detected_object': class_name,\n",
    "            'confidence': confidence\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # ספירת קטגוריות\n",
    "    category_counts = Counter(df['detected_object'])\n",
    "    print(f\"\\nסך הכל {len(category_counts)} קטגוריות שונות זוהו\")\n",
    "    print(\"\\nהקטגוריות הנפוצות ביותר:\")\n",
    "    for cat, count in category_counts.most_common(15):\n",
    "        print(f\"  {cat}: {count}\")\n",
    "    \n",
    "    # שמירת ה-9 הקטגוריות הנפוצות ביותר\n",
    "    top_categories = [cat for cat, _ in category_counts.most_common(max_categories - 1)]\n",
    "    \n",
    "    # סיווג כל דבר אחר כ-'other'\n",
    "    df['final_category'] = df['detected_object'].apply(\n",
    "        lambda x: x if x in top_categories else 'other'\n",
    "    )\n",
    "    \n",
    "    # שמירת CSV\n",
    "    df_output = df[['image_id', 'final_category', 'confidence', 'image_path']]\n",
    "    df_output.to_csv(output_csv, index=False, encoding='utf-8')\n",
    "    \n",
    "    print(f\"\\nCSV נשמר ב: {output_csv}\")\n",
    "    print(f\"מספר קטגוריות סופי: {len(df['final_category'].unique())}\")\n",
    "    print(\"\\nהתפלגות קטגוריות סופית:\")\n",
    "    print(df['final_category'].value_counts())\n",
    "    \n",
    "    return df, top_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# יצירת CSV לכל סט\n",
    "print(\"=== Train Dataset ===\")\n",
    "train_df, top_categories = create_csv_with_top_categories(train_results, \"train_labels.csv\")\n",
    "\n",
    "print(\"\\n=== Test Dataset ===\")\n",
    "test_df, _ = create_csv_with_top_categories(test_results, \"test_labels.csv\")\n",
    "\n",
    "print(\"\\n=== Validation Dataset ===\")\n",
    "val_df, _ = create_csv_with_top_categories(val_results, \"val_labels.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: משימה 3 - הכנת דאטהסט ללמידת מכונה (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# הגדרות\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "IMG_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(df, img_height=IMG_HEIGHT, img_width=IMG_WIDTH):\n",
    "    \"\"\"\n",
    "    ממיר תמונות למערכים (X) ומכין תוויות (Y)\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    print(f\"טוען {len(df)} תמונות...\")\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        if (idx + 1) % 100 == 0:\n",
    "            print(f\"טעון {idx + 1}/{len(df)} תמונות\")\n",
    "        \n",
    "        try:\n",
    "            img_path = row['image_path']\n",
    "            \n",
    "            # טעינת תמונה\n",
    "            img = load_img(img_path, target_size=(img_height, img_width))\n",
    "            img_array = img_to_array(img)\n",
    "            \n",
    "            # נורמליזציה [0, 1]\n",
    "            img_array = img_array / 255.0\n",
    "            \n",
    "            X.append(img_array)\n",
    "            y.append(row['final_category'])\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    X = np.array(X)\n",
    "    print(f\"\\nX shape: {X.shape}\")\n",
    "    print(f\"Number of labels: {len(y)}\")\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# הכנת דאטהסטים\n",
    "print(\"\\n=== הכנת Train Dataset ===\")\n",
    "X_train, y_train = prepare_dataset(train_df)\n",
    "\n",
    "print(\"\\n=== הכנת Test Dataset ===\")\n",
    "X_test, y_test = prepare_dataset(test_df)\n",
    "\n",
    "print(\"\\n=== הכנת Validation Dataset ===\")\n",
    "X_val, y_val = prepare_dataset(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# קידוד תוויות\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)  # fit על train בלבד\n",
    "\n",
    "y_train_encoded = label_encoder.transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "\n",
    "# One-hot encoding\n",
    "num_classes = len(label_encoder.classes_)\n",
    "y_train_cat = to_categorical(y_train_encoded, num_classes)\n",
    "y_test_cat = to_categorical(y_test_encoded, num_classes)\n",
    "y_val_cat = to_categorical(y_val_encoded, num_classes)\n",
    "\n",
    "print(f\"\\nמספר קטגוריות: {num_classes}\")\n",
    "print(f\"קטגוריות: {label_encoder.classes_}\")\n",
    "print(f\"\\ny_train_cat shape: {y_train_cat.shape}\")\n",
    "print(f\"y_test_cat shape: {y_test_cat.shape}\")\n",
    "print(f\"y_val_cat shape: {y_val_cat.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: משימה 4 - בניית רשת CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    בניית מודל CNN משופר\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        # Block 1\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Block 2\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Block 3\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Dense layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# בניית המודל\n",
    "input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "model = build_cnn_model(input_shape, num_classes)\n",
    "\n",
    "# הצגת המבנה\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# קומפילציה עם אופטימייזר משופר\n",
    "# נשתמש ב-Adam עם learning rate scheduling\n",
    "initial_learning_rate = 0.001\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.9,\n",
    "    staircase=True\n",
    ")\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks לשיפור האימון\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    'best_model.keras',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# אימון המודל\n",
    "print(\"\\n=== מתחיל אימון ===\")\n",
    "history = model.fit(\n",
    "    X_train, y_train_cat,\n",
    "    batch_size=32,\n",
    "    epochs=50,\n",
    "    validation_data=(X_test, y_test_cat),\n",
    "    callbacks=[early_stopping, reduce_lr, checkpoint],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# גרפים של האימון\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Accuracy\n",
    "axes[0].plot(history.history['accuracy'], label='Train Accuracy')\n",
    "axes[0].plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_title('Model Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Loss\n",
    "axes[1].plot(history.history['loss'], label='Train Loss')\n",
    "axes[1].plot(history.history['val_loss'], label='Validation Loss')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].set_title('Model Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nGרף האימון נשמר ב: training_history.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: משימה 5 - הערכת המודל על Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# הערכה על Train\n",
    "print(\"=== הערכה על Train ===\")\n",
    "train_loss, train_accuracy = model.evaluate(X_train, y_train_cat, verbose=0)\n",
    "print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "# הערכה על Test\n",
    "print(\"\\n=== הערכה על Test ===\")\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_cat, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# הערכה על Validation\n",
    "print(\"\\n=== הערכה על Validation ===\")\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val_cat, verbose=0)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# חיזויים על Validation\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_val_pred_classes = np.argmax(y_val_pred, axis=1)\n",
    "y_val_true_classes = np.argmax(y_val_cat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_val_true_classes, y_val_pred_classes)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=label_encoder.classes_,\n",
    "    yticklabels=label_encoder.classes_\n",
    ")\n",
    "plt.title('Confusion Matrix - Validation Set', fontsize=16)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nConfusion Matrix נשמר ב: confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(\"\\n=== Classification Report - Validation Set ===\")\n",
    "print(classification_report(\n",
    "    y_val_true_classes,\n",
    "    y_val_pred_classes,\n",
    "    target_names=label_encoder.classes_\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## סיכום ומסקנות"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"                    סיכום תוצאות                    \")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n1. זיהוי אובייקטים עם YOLO:\")\n",
    "print(f\"   - Train: {len(train_results)} תמונות\")\n",
    "print(f\"   - Test: {len(test_results)} תמונות\")\n",
    "print(f\"   - Validation: {len(val_results)} תמונות\")\n",
    "\n",
    "print(f\"\\n2. מספר קטגוריות: {num_classes}\")\n",
    "print(f\"   קטגוריות: {', '.join(label_encoder.classes_)}\")\n",
    "\n",
    "print(f\"\\n3. גודל דאטהסט:\")\n",
    "print(f\"   - X_train: {X_train.shape}\")\n",
    "print(f\"   - X_test: {X_test.shape}\")\n",
    "print(f\"   - X_val: {X_val.shape}\")\n",
    "\n",
    "print(f\"\\n4. ביצועי המודל:\")\n",
    "print(f\"   - Train Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"   - Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"   - Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "print(f\"\\n5. מסקנות:\")\n",
    "if train_accuracy - val_accuracy > 0.1:\n",
    "    print(\"   ⚠️ נראה שיש overfitting - הדיוק על train גבוה משמעותית מ-validation\")\n",
    "    print(\"   💡 מומלץ להוסיף regularization או data augmentation\")\n",
    "elif val_accuracy > 0.8:\n",
    "    print(\"   ✅ המודל משיג ביצועים טובים על ה-validation set\")\n",
    "    print(\"   ✅ הדיוק מעל 80% מעיד על סיווג אפקטיבי\")\n",
    "elif val_accuracy > 0.6:\n",
    "    print(\"   ⚠️ המודל משיג ביצועים בינוניים\")\n",
    "    print(\"   💡 מומלץ להגדיל את מספר ה-epochs או לשפר את המודל\")\n",
    "else:\n",
    "    print(\"   ❌ המודל זקוק לשיפור משמעותי\")\n",
    "    print(\"   💡 מומלץ לבדוק את איכות הדאטה ולשפר את ארכיטקטורת המודל\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# שמירת המודל הסופי\n",
    "model.save('final_cnn_model.keras')\n",
    "print(\"\\nהמודל הסופי נשמר ב: final_cnn_model.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
